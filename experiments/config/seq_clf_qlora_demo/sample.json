{
    "project_name": "seq_clf_qlora_demo",
    "data_dir": "",
    "data_prefix": "clf",
    "model_dir": "clf_demo",
	"pretrained_model": "EleutherAI/polyglot-ko-5.8b",
	"lora_r": 8,
	"lora_alpha": 16,
	"lora_dropout": 0.1,
    "max_length" : 256,
    "per_device_batch_size": 16,
    "gradient_accumulation_steps": 1,
    "epochs": 50,
    "learning_rate": 2e-6,
    "label_smoothing_factor": 0,
    "save_steps": 80,
    "summary_step": 80,
    "save_total_limit": 1,
    "metric_for_best_model": "eval_loss",
    "seed": 100,
    "fp16": true,
    "bf16": false,
    "qlora": true,
    "ddp_find_unused_parameters": false
}